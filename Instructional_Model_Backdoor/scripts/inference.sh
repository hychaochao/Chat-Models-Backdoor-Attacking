python inference.py \
    --model_path path/to/your/model \
    --temperature 0.9 \
    --top_p 0.75 \
    --data_file path/to/your/data \
    --predictions_file path/to/prediction/data \
    --with_prompt \
    --max_new_tokens 256